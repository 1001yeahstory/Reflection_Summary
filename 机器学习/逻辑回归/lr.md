# LR推导，基础5连问
- 基础公式
    - f(x) = wx + b
    - y = sigmoid(f(x))
    - 可以看作是一次线性拟合+一次sigmoid的非线性变化
- 伯努利过程
    - 对于lr来说事情只有发生和不发生两种可能，对于已知样本来说，满足伯努利的概率假设：
        - p(y=1/x,θ) = h(θ,x)
        - p(y=0/x,θ) = 1-h(θ,x)
        - p(y/x,θ) = h(θ,x)^y · (1-h(θ,x))^(1-y) 
            - 第i个样本正确预测的概率如上可得
    - 几率odds
        - 数据特征下属于正例及反例的比值
        - ln(y/(1-y))
- 极大似然
    - 第i个样本正确预测的概率如上可得每条样本的情况下
    - 综合全部样本发生的概率都要最大的话，采取极大似然连乘可得：
        - ∏(h(θ,x)^y · (1-h(θ,x))^(1-y))
- 损失函数
    - 通常会对极大似然取对数，得到损失函数，方便计算
        - ∑ylogh(θ,x)+(1-y)log(1-h(θ,x))最大
        - 及-1/m · ∑ylogh(θ,x)+(1-y)log(1-h(θ,x))最小    
- 梯度下降
    - 损失函数求偏导，更新θ
    - θj+1 = θj - ∆·∂Loss/∂θ =θj - ∆·1/m·∑x·(h-y)
        - ∆为学习率

# LR明明是分类模型为什么叫回归？
观测样本中该特征在正负类中出现概率的比值满足线性条件，用的是线性拟合比率值，所以叫回归

# 为什么LR可以用来做CTR预估？
1. 点击行为为正向，未点击行为为负向，ctr需要得到点击行为的概率，lr可以产出正向行为的概率，完美match
2. 实现简单，方便并行，计算迭代速度很快
3. 可解释性强，可结合正则化等优化方法

# 满足什么样条件的数据用LR最好？
- 特征之间尽可能独立
    - 不独立所以我们把不独立的特征交叉了
        - 还记得FM的思路？
- 离散特征
    - 连续特征通常没有特别含义，31岁和32岁差在哪？
    - 离散特征方便交叉考虑
    - 在异常值处理上也更加方便
    - 使的lr满足分布假设
        - 什么分布假设？
- 在某种确定分类上的特征分布满足高斯分布
    - ![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8wh7dd6bkj310w034gmb.jpg)
    - C1和C2为正负类，观测样本中该特征在正负类中出现概率的比值满足线性条件的前提就是P服从正太分布
        - 实际中不满足的很多，不满足我们通常就离散化，oneHotEncode

此处就用到了全概率公式推导，有可能会回到[写出全概率公式&贝叶斯公式](基础概念/先验概率和后验概率/先验概率和后验概率.md#L96)的问题中

# LR为什么使用sigmoid函数作为激活函数？其他函数不行吗？
- 思路一：lr的前提假设就是几率odds满足线性回归，odds又为正负样本的log比，参见`满足什么样条件的数据用LR最好？`中第三点公式的展开
- 思路二：Exponential model 的形式是这样的：假设第i个特征对第k类的贡献是![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8wmq11x6zj300s00f3y9.jpg)，则数据点![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8wmqpotqfj302700imwx.jpg)属于第k类的概率正比于![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8wmrp4qv4j305b00i0sj.jpg)。
    - 二分类上：![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8wmsc1vfkj30jm036wet.jpg)
    - 化简即为sigmoid
    
# 我的总结：
- 逻辑回归假设观测样本中该特征在正负类中出现结果服从伯努利分布，通过极大化似然函数的方法，运用梯度下降来求解参数，来达到将数据二分类的目的