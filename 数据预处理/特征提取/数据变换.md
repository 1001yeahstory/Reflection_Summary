# 为什么需要对数据进行变换？
- 避免异常点：比如对连续变量进行份桶离散化
- 可解释性或者需要连续输出：比如评分卡模型中的iv+woe
- 使得原始数据的信息量更大：比如log/sqrt变换

# 归一化和标准化之间的关系？
- 归一化
    - 通过改变数值范围，使各个特征维度对目标函数的影响权重是一致的，即使得那些扁平分布的数据伸缩变换成类球形
    - 作用：
        - 提高精度
        - 提高速度
- 标准化
    - 通过在不改变原始分布的情况下，使得不同分布之间可以相互比较，常用伸缩变换，内部的相对分布是不会变的
    - 作用：
        - 不同的度量之间不仅仅是数值而且是空间内可比
        - 不改变原始分布
- 总结
    - 通常，我会在特征之间差异范围特别大的时候，比如一些特征是\[0,1]一些特征是\[-e100,e100]进行特征之间的交叉的时候会考虑z-score，而当特征都差不多范围，而我一般也会使用类似min-max进行加速收敛        

# 常用方法
- 截断
    - 连续型的数值进行截断或者对长尾数据进行对数后截断(保留重要信息的前提下对特征进行截断,截断后的特征也可以看作是类别特征)
    - 参考异常点里面的outlier识别，以最大值填充或者以None
- 二值化
    - 数据分布过于不平衡
    - 空值/异常值过多
- 分桶
    - 小范围连续数据内不存在逻辑关系，比如31岁和32岁之间不存在明显的差异，可以归为一类
- 离散化    
    - 数值无意义，比如学历、祖籍等等
- 缩放
    - z-score标准化
    - min-max归一化
    - 范数归一化:![](https://tva1.sinaimg.cn/large/006y8mN6gy1g8mf5xdj2sj3031011jr6.jpg)
        - L1范数
        - L2范数:
    - 平方根缩放
    - 对数缩放
        - 对数缩放适用于处理长尾分且取值为正数的数值变量
            - 它将大端长尾压缩为短尾，并将小端进行延伸
    - Box-Cox转换
        - ![](https://tva1.sinaimg.cn/large/006y8mN6ly1g8mfjjwir3j309m038gln.jpg)
        - 通过因变量的变换，使得变换后的y(λ)与自变量具有线性依托关系。因此，Box-Cox变换是通过参数的适当选择，达到对原来数据的“综合治理”，使其满足一个线性模型条件
- 缺失值填充
    - 直接填充
        - 均值
        - 中位数
        - 众数
        - 分位数
    - 模型插值
        - 有效性存疑，取决于特征列数
    - 新增列空值特征
        - 连续特征分桶
        - 离散特征新增category
- 特征交叉
    - 人为分段交叉
        - 提升模型的拟合能力，使基向量更有表示能力
        - 离散变量的交并补
        - 连续变量的点积
    - 自动组合
        - FM/FFM中的矩阵点积
        - Neural Network里面的dense
    - 条件选择
        - 通过树或者类似的特征组合模型去做最低熵的特征选择
- 非线性编码
    - 核向量进行升维
    - 树模型的叶子结点的stack
    - 谱聚类/pca/svd等信息抽取编码
    - lda/EM等分布拟合表示
